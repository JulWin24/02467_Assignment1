{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "> **Github repository**: [02467_Assignment1](https://github.com/JulWin24/02467_Assignment1)\n",
    ">\n",
    "> **Group members**:\n",
    "> - Rune Harlyk (s234814)\n",
    "> - Joseph Nguyen (s)\n",
    "> - Julius Winkel (s234862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Web-scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ic2s2-2023.org/program\"\n",
    "\n",
    "req = requests.get(url)\n",
    "soup = BeautifulSoup(req.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 1475 plenary names\n",
      "Found: 10 keynotes names\n",
      "Found: 49 chair names\n",
      "Found: 1491 names in total\n"
     ]
    }
   ],
   "source": [
    "names = set()\n",
    "\n",
    "def get_plenary_names(names, soup): \n",
    "    new_names = {name.strip() for nav_list in soup.find_all(\"ul\", class_=\"nav_list\") \n",
    "        for i in nav_list.find_all(\"i\") \n",
    "        for name in i.get_text(strip=True).split(\",\")}\n",
    "    print(f\"Found: {len(new_names)} plenary names\")\n",
    "    names.update(new_names)\n",
    "\n",
    "def get_keynotes_names(names, soup):\n",
    "    new_names = {a.get_text(strip=True).replace(\"Keynote - \", \"\") \n",
    "        for a in soup.find_all(\"a\", href=lambda x: x and x.startswith(\"/keynotes#\"))}\n",
    "    print(f\"Found: {len(new_names)} keynotes names\")\n",
    "    names.update(new_names)\n",
    "    \n",
    "def get_chair_names(names, soup):\n",
    "    new_names = {i.get_text(strip=True).replace(\"Chair: \", \"\") \n",
    "          for i in soup.find_all(\"i\") if i.get_text(strip=True).startswith(\"Chair:\")}\n",
    "    print(f\"Found: {len(new_names)} chair names\")\n",
    "    names.update(new_names)\n",
    "\n",
    "get_plenary_names(names, soup)\n",
    "get_keynotes_names(names, soup)\n",
    "get_chair_names(names, soup)\n",
    "\n",
    "print(f\"Found: {len(names)} names in total\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: 1486 names\n",
      "After fuzzing: 1460 names\n"
     ]
    }
   ],
   "source": [
    "def clean_name(name):\n",
    "    name = unidecode(name)\n",
    "    return name\n",
    "\n",
    "def clean_names(names):\n",
    "    names = {clean_name(name) for name in names}\n",
    "    return names\n",
    "\n",
    "def fuzz_names(names, threshold=90):\n",
    "    names_list = sorted(names)\n",
    "    name_groups = defaultdict(list)\n",
    "\n",
    "    for name in names_list:\n",
    "        first_letter = name[0] if name else \"\"\n",
    "        name_groups[first_letter].append(name)\n",
    "\n",
    "    merge_map = {}\n",
    "    for letter, group in name_groups.items():\n",
    "        for i, name in enumerate(group):\n",
    "            for j in range(i + 1, len(group)):\n",
    "                match_name = group[j]\n",
    "                score = fuzz.ratio(name, match_name)\n",
    "                if score >= threshold:\n",
    "                    merge_map[match_name] = name\n",
    "\n",
    "    merged_names = set()\n",
    "    for name in names_list:\n",
    "        standardized_name = merge_map.get(name, name)\n",
    "        merged_names.add(standardized_name)\n",
    "\n",
    "    return merged_names\n",
    "\n",
    "names = clean_names(names)\n",
    "print(f\"After cleaning: {len(names)} names\")\n",
    "\n",
    "names = fuzz_names(names)\n",
    "print(f\"After fuzzing: {len(names)} names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('author_names_2023.txt', 'w', encoding=\"utf8\") as f:\n",
    "    for name in sorted(names):\n",
    "        f.write(f\"{name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Ready Made vs Custom Made Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Gathering Research Articles using the OpenAlex API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading researches 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_file = \"author_names_2024.txt\"\n",
    "data_file = \"author_data.csv\"\n",
    "\n",
    "with open(names_file, 'r', encoding=\"utf8\") as f:\n",
    "    names = f.read().splitlines()\n",
    "\n",
    "print(f\"Loaded names: {len(names)}\")\n",
    "names = clean_names(names)\n",
    "\n",
    "names = fuzz_names(names)\n",
    "print(f\"After fuzzing: {len(names)} names\")\n",
    "\n",
    "names = sorted(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The Network of Computational Social Scientists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
